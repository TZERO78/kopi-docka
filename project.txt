## Project Structure

```

## File: setup.py

```python
"""
Setup script for Kopia-Docka.

This script configures the package for installation via pip.
"""

from setuptools import setup, find_packages
from pathlib import Path

# Read README for long description
readme_file = Path(__file__).parent / 'README.md'
long_description = ''
if readme_file.exists():
    with open(readme_file, 'r', encoding='utf-8') as f:
        long_description = f.read()

setup(
    name='kopia-docka',
    version='1.0.0',
    description='A robust backup solution for Docker environments using Kopia',
    long_description=long_description,
    long_description_content_type='text/markdown',
    author='Kopia-Docka Development Team',
    author_email='admin@example.com',
    url='https://github.com/yourusername/kopia-docka',
    license='MIT',
    
    packages=find_packages(),
    include_package_data=True,
    
    python_requires='>=3.8',
    
    install_requires=[
        'psutil>=5.9.0',
    ],
    
    extras_require={
        'dev': [
            'pytest>=7.0.0',
            'pytest-cov>=3.0.0',
            'black>=22.0.0',
            'flake8>=4.0.0',
            'mypy>=0.950',
        ],
    },
    
    entry_points={
        'console_scripts': [
            'kopia-docka=kopia_docka.__main__:main',
        ],
    },
    
    classifiers=[
        'Development Status :: 4 - Beta',
        'Environment :: Console',
        'Intended Audience :: System Administrators',
        'License :: OSI Approved :: MIT License',
        'Operating System :: POSIX :: Linux',
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.8',
        'Programming Language :: Python :: 3.9',
        'Programming Language :: Python :: 3.10',
        'Programming Language :: Python :: 3.11',
        'Topic :: System :: Archiving :: Backup',
        'Topic :: System :: Systems Administration',
    ],
    
    keywords='docker backup kopia containers volumes database',
)


## File: requirements.txt

psutil>=5.9.0


## File: config.template.ini

# Kopia-Docka Configuration Template
# 
# This is a template configuration file for Kopia-Docka.
# Copy this file and modify it according to your needs.
# 
# Default locations:
#   - System-wide (root): /etc/kopia-docka.conf
#   - User: ~/.config/kopia-docker/config.conf

[kopia]
# Path where Kopia repository will be stored
repository_path = /backup/kopia-repository

# Repository password (will be auto-generated on first run if not set)
# IMPORTANT: Keep this password safe! You'll need it to restore backups.
password = CHANGE_ME_TO_A_SECURE_PASSWORD

# Compression algorithm (zstd, gzip, or none)
compression = zstd

# Encryption algorithm
encryption = AES256-GCM-HMAC-SHA256

# Cache directory for Kopia
cache_directory = /var/cache/kopia-docka

[backup]
# Base path for temporary backup operations
base_path = /backup/kopia-docka

# Number of parallel workers for backup operations
# Set to 'auto' to automatically determine based on system resources
# Or specify a number (e.g., 4)
parallel_workers = auto

# Timeout in seconds for stopping containers
stop_timeout = 30

# Timeout in seconds for starting containers
start_timeout = 60

# Comma-separated list of file patterns to exclude from backups
exclude_patterns = *.tmp,*.temp,*.log,.git/,__pycache__/,*.pyc

# Enable database backup using native dump tools
database_backup = true

# Verify snapshots after creation (slower but safer)
verify_after_backup = false

[docker]
# Path to Docker socket
socket = /var/run/docker.sock

# Timeout for docker-compose operations
compose_timeout = 300

# Remove stopped containers before backup
prune_stopped_containers = false

[logging]
# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
level = INFO

# Log file path
file = /var/log/kopia-docka.log

# Maximum log file size in MB
max_size_mb = 100

# Number of backup log files to keep
backup_count = 5

[schedule]
# Enable scheduled backups (requires cron or systemd timer setup)
enabled = false

# Daily backup time (24-hour format)
daily_at = 02:00

# Weekly backup day (monday, tuesday, etc.)
weekly_on = sunday

# Monthly backup day (1-31)
monthly_on = 1

# Retention policies (number of backups to keep)
retention_daily = 7
retention_weekly = 4
retention_monthly = 12

# Advanced retention settings
# Minimum age before considering for deletion (days)
retention_min_age = 1

# Keep at least this many recent backups regardless of age
retention_min_count = 3


## File: README.md

# Kopia-Docka

A robust, production-grade backup solution for Docker environments using Kopia as the backend storage engine.

## Overview

Kopia-Docka implements a "Cold Backup" strategy that ensures 100% data consistency by stopping containers during backup while minimizing overall system downtime through sequential processing of logical backup units.

## Features

- **Automatic Discovery**: Identifies all running Docker containers and groups them into logical units
- **Smart Grouping**: Recognizes Docker Compose stacks and treats them as single backup units
- **Minimal Downtime**: Sequential unit-by-unit backup minimizes service interruption
- **Database Support**: Native backup for PostgreSQL, MySQL, MongoDB, and Redis
- **Parallel Processing**: Configurable parallel workers for optimal performance
- **Interactive Restore**: Wizard-guided restoration process
- **Dry Run Mode**: Preview operations without making changes
- **System Aware**: Automatically adjusts to available system resources

## Installation

### Prerequisites

- Linux operating system
- Docker installed and running
- Python 3.8 or higher
- Kopia backup tool
- Root or sudo access (for Docker operations)

### Install Kopia

```bash
# Debian/Ubuntu
curl -s https://kopia.io/signing-key | sudo apt-key add -
echo "deb http://packages.kopia.io/apt/ stable main" | sudo tee /etc/apt/sources.list.d/kopia.list
sudo apt update
sudo apt install kopia

# Or download directly
wget https://github.com/kopia/kopia/releases/latest/download/kopia_linux_amd64
chmod +x kopia_linux_amd64
sudo mv kopia_linux_amd64 /usr/local/bin/kopia
```

### Install Kopia-Docka

```bash
# Clone repository
git clone https://github.com/yourusername/kopia-docka.git
cd kopia-docka

# Install package
pip install -e .

# Or install from PyPI (when available)
pip install kopia-docka
```

## Quick Start

### 1. Initialize Configuration

```bash
# Create default configuration
kopia-docka config --init

# Edit configuration
kopia-docka config --edit
```

### 2. Initialize Kopia Repository

```bash
# Set up the Kopia repository
kopia-docka install
```

### 3. Check System

```bash
# Verify all dependencies and settings
kopia-docka check
```

### 4. Run First Backup

```bash
# Dry run to preview operations
kopia-docka backup --dry-run

# Perform actual backup
kopia-docka backup
```

## Usage

### Backup Operations

```bash
# Backup all units
kopia-docka backup

# Backup specific unit
kopia-docka backup --unit my-stack

# Dry run mode
kopia-docka backup --dry-run
```

### Restore Operations

```bash
# Interactive restore wizard
kopia-docka restore

# List available backups
kopia-docka list --units
```

### Configuration Management

```bash
# Show current configuration
kopia-docka config --show

# Edit configuration
kopia-docka config --edit

# Reinitialize configuration
kopia-docka config --init
```

## Backup Process

The backup process follows these steps for each unit:

1. **Stop**: Gracefully stop all containers in the unit
2. **Backup Recipe**: Save docker-compose.yml and container configurations
3. **Backup Volumes**: Create snapshots of all Docker volumes
4. **Backup Databases**: Perform native dumps for database containers
5. **Start**: Restart all containers in the unit

## Restore Process

The interactive restore wizard guides you through:

1. **Select Restore Point**: Choose from available backups
2. **Restore Recipes**: Recover configuration files
3. **Restore Volumes**: Recreate Docker volumes with data
4. **Restore Databases**: Import database dumps
5. **Restart Services**: Commands to restart your services

## Configuration

Key configuration options in `/etc/kopia-docka.conf`:

```ini
[kopia]
repository_path = /backup/kopia-repository
password = <auto-generated-secure-password>
compression = zstd

[backup]
parallel_workers = auto
stop_timeout = 30
database_backup = true

[docker]
socket = /var/run/docker.sock
```

## System Requirements

### Minimum Requirements
- 2GB RAM
- 10GB free disk space
- Docker 20.10+
- Python 3.8+

### Recommended
- 4GB+ RAM
- SSD storage for repository
- Docker 24.0+
- Python 3.10+

## Performance Optimization

Kopia-Docka automatically adjusts performance based on system resources:

| RAM | Workers | Recommendation |
|-----|---------|----------------|
| ≤2GB | 1 | Light workloads |
| ≤4GB | 2 | Small deployments |
| ≤8GB | 4 | Medium deployments |
| ≤16GB | 8 | Large deployments |
| >16GB | 12 | Enterprise deployments |

## Scheduling Backups

### Using Cron

```bash
# Add to crontab
0 2 * * * /usr/local/bin/kopia-docka backup >> /var/log/kopia-docka-cron.log 2>&1
```

### Using Systemd

Create `/etc/systemd/system/kopia-docka.service`:

```ini
[Unit]
Description=Kopia-Docka Backup
After=docker.service

[Service]
Type=oneshot
ExecStart=/usr/local/bin/kopia-docka backup
User=root

[Install]
WantedBy=multi-user.target
```

Create `/etc/systemd/system/kopia-docka.timer`:

```ini
[Unit]
Description=Daily Kopia-Docka Backup

[Timer]
OnCalendar=daily
OnCalendar=02:00
Persistent=true

[Install]
WantedBy=timers.target
```

Enable timer:
```bash
systemctl enable kopia-docka.timer
systemctl start kopia-docka.timer
```

## Troubleshooting

### Common Issues

**Docker Permission Denied**
```bash
# Add user to docker group
sudo usermod -aG docker $USER
# Or run with sudo
sudo kopia-docka backup
```

**Kopia Repository Not Found**
```bash
# Initialize repository
kopia-docka install
```

**Insufficient Disk Space**
```bash
# Check available space
df -h /backup
# Clean old snapshots
kopia snapshot list
kopia snapshot delete --id=<snapshot-id>
```

### Debug Mode

```bash
# Run with verbose output
kopia-docka -v backup

# Check logs
tail -f /var/log/kopia-docka.log
```

## Security Considerations

- **Password Protection**: Repository password is auto-generated and stored in config
- **Encryption**: All backups are encrypted using AES256-GCM
- **File Permissions**: Configuration files are created with 600 permissions
- **Container Isolation**: Backups run in the host namespace with minimal privileges

## Best Practices

1. **Test Restores**: Regularly verify backup integrity by performing test restores
2. **Monitor Disk Space**: Ensure adequate space for repository growth
3. **Secure Password**: Store the repository password in a secure location
4. **Regular Maintenance**: Run `kopia maintenance run` periodically
5. **Offsite Copies**: Replicate repository to remote storage

## License

MIT License - See LICENSE file for details

## Contributing

Contributions are welcome! Please read CONTRIBUTING.md for guidelines.

## Support

- Issue Tracker: https://github.com/yourusername/kopia-docka/issues
- Documentation: https://github.com/yourusername/kopia-docka/wiki

## Acknowledgments

- Kopia backup tool: https://kopia.io
- Docker: https://docker.com
- The open source community

## File: kopia_docka/dry_run.py

```python
"""
Dry run simulation module for Kopia-Docka.

This module provides functionality to simulate backup operations without
actually performing them, allowing users to preview what will happen.
"""

import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any

from .types import BackupUnit
from .config import Config
from .system_utils import SystemUtils


logger = logging.getLogger(__name__)


class DryRunReport:
    """
    Generates dry run reports for backup operations.
    
    This class simulates backup operations and provides detailed reports
    about what would happen during an actual backup.
    """
    
    def __init__(self, config: Config):
        """
        Initialize dry run reporter.
        
        Args:
            config: Application configuration
        """
        self.config = config
        self.utils = SystemUtils()
    
    def generate(self, units: List[BackupUnit]):
        """
        Generate and display dry run report.
        
        Args:
            units: List of backup units to analyze
        """
        print("\n" + "=" * 70)
        print("KOPIA-DOCKA DRY RUN REPORT")
        print("=" * 70)
        
        print(f"\nSimulation Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Configuration File: {self.config.config_file}")
        
        # System information
        self._print_system_info()
        
        # Backup units summary
        self._print_units_summary(units)
        
        # Detailed unit analysis
        for unit in units:
            self._analyze_unit(unit)
        
        # Time and resource estimates
        self._print_estimates(units)
        
        # Configuration review
        self._print_config_review()
        
        print("\n" + "=" * 70)
        print("END OF DRY RUN REPORT")
        print("=" * 70)
        print("\nNo changes were made. Run without --dry-run to perform actual backup.")
    
    def _print_system_info(self):
        """Print system information."""
        print("\n### SYSTEM INFORMATION ###")
        print(f"Available RAM: {self.utils.get_available_ram():.2f} GB")
        print(f"CPU Cores: {self.utils.get_cpu_count()}")
        print(f"Parallel Workers: {self.config.parallel_workers}")
        print(f"Backup Path: {self.config.backup_base_path}")
        print(f"Repository Path: {self.config.kopia_repository_path}")
        
        # Check disk space
        repo_space = self.utils.get_available_disk_space(
            str(self.config.kopia_repository_path.parent)
        )
        print(f"Available Disk Space: {repo_space:.2f} GB")
        
        # Check dependencies
        print("\n### DEPENDENCY CHECK ###")
        checks = [
            ("Docker", self.utils.check_docker()),
            ("Kopia", self.utils.check_kopia()),
            ("Tar", self.utils.check_tar()),
        ]
        
        for name, available in checks:
            status = "✓ Available" if available else "✗ Missing"
            print(f"{name}: {status}")
        
        # Docker version
        docker_version = self.utils.get_docker_version()
        if docker_version:
            print(f"Docker Version: {'.'.join(map(str, docker_version))}")
        
        # Kopia version
        kopia_version = self.utils.get_kopia_version()
        if kopia_version:
            print(f"Kopia Version: {kopia_version}")
    
    def _print_units_summary(self, units: List[BackupUnit]):
        """
        Print summary of backup units.
        
        Args:
            units: List of backup units
        """
        print("\n### BACKUP UNITS SUMMARY ###")
        print(f"Total Units: {len(units)}")
        
        stacks = [u for u in units if u.type == 'stack']
        standalone = [u for u in units if u.type == 'standalone']
        
        print(f"  - Stacks: {len(stacks)}")
        print(f"  - Standalone Containers: {len(standalone)}")
        
        total_containers = sum(len(u.containers) for u in units)
        total_volumes = sum(len(u.volumes) for u in units)
        
        print(f"Total Containers: {total_containers}")
        print(f"Total Volumes: {total_volumes}")
        
        # Database containers
        db_containers = sum(len(u.get_database_containers()) for u in units)
        if db_containers > 0:
            print(f"Database Containers: {db_containers}")
    
    def _analyze_unit(self, unit: BackupUnit):
        """
        Analyze a single backup unit.
        
        Args:
            unit: Backup unit to analyze
        """
        print(f"\n### UNIT: {unit.name} ###")
        print(f"Type: {unit.type}")
        print(f"Containers: {len(unit.containers)}")
        
        # List containers
        for container in unit.containers:
            status = "Running" if container.is_running else "Stopped"
            db_info = f" [DB: {container.database_type}]" if container.is_database else ""
            print(f"  - {container.name} ({container.image}) - {status}{db_info}")
        
        # Compose file
        if unit.compose_file:
            print(f"Compose File: {unit.compose_file}")
        
        # Volumes
        if unit.volumes:
            print(f"Volumes: {len(unit.volumes)}")
            total_size = 0
            for volume in unit.volumes:
                size = volume.size_bytes or 0
                total_size += size
                size_str = self.utils.format_bytes(size) if size > 0 else "Unknown"
                print(f"  - {volume.name}: {size_str}")
            
            if total_size > 0:
                print(f"Total Volume Size: {self.utils.format_bytes(total_size)}")
        
        # Estimated operations
        print("Operations:")
        print(f"  1. Stop {len(unit.running_containers)} containers")
        print(f"  2. Backup recipes (compose + inspect data)")
        print(f"  3. Backup {len(unit.volumes)} volumes")
        
        db_containers = unit.get_database_containers()
        if db_containers:
            print(f"  4. Backup {len(db_containers)} databases")
        
        print(f"  5. Start {len(unit.running_containers)} containers")
    
    def _print_estimates(self, units: List[BackupUnit]):
        """
        Print time and resource estimates.
        
        Args:
            units: List of backup units
        """
        print("\n### TIME AND RESOURCE ESTIMATES ###")
        
        # Calculate total data size
        total_size = 0
        for unit in units:
            total_size += unit.total_volume_size
        
        if total_size > 0:
            print(f"Estimated Data Size: {self.utils.format_bytes(total_size)}")
        
        # Time estimates (rough approximations)
        estimated_time_per_unit = timedelta(minutes=5)  # Base time
        
        for unit in units:
            # Add time based on volume size
            volume_gb = unit.total_volume_size / (1024**3)
            volume_time = timedelta(minutes=volume_gb * 2)  # 2 min per GB
            
            # Add time for databases
            db_time = timedelta(minutes=len(unit.get_database_containers()) * 3)
            
            estimated_time_per_unit += volume_time + db_time
        
        total_time = estimated_time_per_unit.total_seconds() / len(units) if units else 0
        
        print(f"Estimated Total Time: {self.utils.format_duration(total_time * len(units))}")
        print(f"Estimated Downtime per Unit: ~30-60 seconds")
        
        # Disk space requirements
        compression_ratio = 0.5  # Assume 50% compression
        required_space = total_size * compression_ratio
        
        if required_space > 0:
            print(f"Estimated Repository Space Required: "
                  f"{self.utils.format_bytes(int(required_space))}")
        
        # Check if enough space
        available_space = self.utils.get_available_disk_space(
            str(self.config.kopia_repository_path.parent)
        )
        
        if required_space > 0 and available_space * (1024**3) < required_space:
            print("⚠️  WARNING: Insufficient disk space for backup!")
    
    def _print_config_review(self):
        """Print configuration review."""
        print("\n### CONFIGURATION REVIEW ###")
        
        config_items = [
            ("Repository Path", self.config.kopia_repository_path),
            ("Backup Base Path", self.config.backup_base_path),
            ("Parallel Workers", self.config.parallel_workers),
            ("Stop Timeout", f"{self.config.get('backup', 'stop_timeout')}s"),
            ("Start Timeout", f"{self.config.get('backup', 'start_timeout')}s"),
            ("Compression", self.config.get('kopia', 'compression')),
            ("Encryption", self.config.get('kopia', 'encryption')),
            ("Database Backup", self.config.getboolean('backup', 'database_backup')),
            ("Verify After Backup", self.config.getboolean('backup', 'verify_after_backup')),
        ]
        
        for name, value in config_items:
            print(f"{name}: {value}")
        
        # Exclusions
        exclude_patterns = self.config.getlist('backup', 'exclude_patterns')
        if exclude_patterns:
            print(f"Exclude Patterns: {', '.join(exclude_patterns)}")
    
    def estimate_backup_duration(self, unit: BackupUnit) -> float:
        """
        Estimate backup duration for a unit.
        
        Args:
            unit: Backup unit
            
        Returns:
            Estimated duration in seconds
        """
        base_time = 30  # Base overhead
        
        # Time for stopping/starting containers
        container_time = len(unit.containers) * 5
        
        # Time for volumes (estimate based on size)
        volume_time = 0
        for volume in unit.volumes:
            if volume.size_bytes:
                # Estimate 100 MB/s throughput
                volume_time += volume.size_bytes / (100 * 1024 * 1024)
        
        # Time for databases
        db_time = len(unit.get_database_containers()) * 60
        
        return base_time + container_time + volume_time + db_time

## File: kopia_docka/system_utils.py

```python
"""
System utilities module for Kopia-Docka.

This module provides system-level utilities including resource monitoring,
dependency checking, and optimization calculations.
"""

import logging
import os
import subprocess
import shutil
from pathlib import Path
from typing import Optional, Tuple

import psutil

from .constants import RAM_WORKER_THRESHOLDS


logger = logging.getLogger(__name__)


class SystemUtils:
    """
    System utilities for resource management and dependency checking.
    
    Provides methods for checking system resources, validating dependencies,
    and calculating optimal configurations based on system capabilities.
    """
    
    @staticmethod
    def check_docker() -> bool:
        """
        Check if Docker is installed and accessible.
        
        Returns:
            True if Docker is available
        """
        try:
            result = subprocess.run(
                ['docker', 'version'],
                capture_output=True,
                text=True,
                timeout=5
            )
            return result.returncode == 0
        except (FileNotFoundError, subprocess.TimeoutExpired):
            return False
    
    @staticmethod
    def check_kopia() -> bool:
        """
        Check if Kopia is installed and accessible.
        
        Returns:
            True if Kopia is available
        """
        return shutil.which('kopia') is not None
    
    @staticmethod
    def check_tar() -> bool:
        """
        Check if tar is installed and accessible.
        
        Returns:
            True if tar is available
        """
        return shutil.which('tar') is not None
    
    @staticmethod
    def get_available_ram() -> float:
        """
        Get available system RAM in gigabytes.
        
        Returns:
            Available RAM in GB
        """
        try:
            memory = psutil.virtual_memory()
            return memory.total / (1024 ** 3)  # Convert to GB
        except Exception as e:
            logger.error(f"Failed to get RAM info: {e}")
            return 2.0  # Conservative default
    
    @staticmethod
    def get_available_disk_space(path: str = '/') -> float:
        """
        Get available disk space in gigabytes.
        
        Args:
            path: Path to check disk space for
            
        Returns:
            Available disk space in GB
        """
        try:
            usage = psutil.disk_usage(path)
            return usage.free / (1024 ** 3)  # Convert to GB
        except Exception as e:
            logger.error(f"Failed to get disk space: {e}")
            return 0.0
    
    @staticmethod
    def get_cpu_count() -> int:
        """
        Get number of CPU cores.
        
        Returns:
            Number of CPU cores
        """
        try:
            return psutil.cpu_count(logical=True) or 1
        except Exception:
            return 1
    
    @staticmethod
    def get_optimal_workers() -> int:
        """
        Calculate optimal number of parallel workers based on system resources.
        
        Returns:
            Recommended number of workers
        """
        ram_gb = SystemUtils.get_available_ram()
        cpu_count = SystemUtils.get_cpu_count()
        
        # Determine workers based on RAM
        ram_workers = 1
        for threshold_gb, workers in RAM_WORKER_THRESHOLDS:
            if ram_gb <= threshold_gb:
                ram_workers = workers
                break
        
        # Don't exceed CPU count
        optimal = min(ram_workers, cpu_count)
        
        logger.debug(f"System has {ram_gb:.1f}GB RAM, {cpu_count} CPUs. "
                    f"Recommending {optimal} workers.")
        
        return optimal
    
    @staticmethod
    def estimate_backup_size(path: str) -> int:
        """
        Estimate size of path for backup.
        
        Args:
            path: Path to estimate
            
        Returns:
            Estimated size in bytes
        """
        try:
            if os.path.isfile(path):
                return os.path.getsize(path)
            
            total_size = 0
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    try:
                        total_size += os.path.getsize(filepath)
                    except (OSError, IOError):
                        continue
            
            return total_size
            
        except Exception as e:
            logger.error(f"Failed to estimate size of {path}: {e}")
            return 0
    
    @staticmethod
    def format_bytes(size_bytes: int) -> str:
        """
        Format bytes into human-readable string.
        
        Args:
            size_bytes: Size in bytes
            
        Returns:
            Formatted string (e.g., "1.5 GB")
        """
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"
    
    @staticmethod
    def format_duration(seconds: float) -> str:
        """
        Format duration into human-readable string.
        
        Args:
            seconds: Duration in seconds
            
        Returns:
            Formatted string (e.g., "2h 15m 30s")
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        parts = []
        if hours > 0:
            parts.append(f"{hours}h")
        if minutes > 0:
            parts.append(f"{minutes}m")
        if secs > 0 or not parts:
            parts.append(f"{secs}s")
        
        return " ".join(parts)
    
    @staticmethod
    def is_root() -> bool:
        """
        Check if running as root.
        
        Returns:
            True if running as root
        """
        return os.geteuid() == 0
    
    @staticmethod
    def ensure_directory(path: Path, mode: int = 0o755):
        """
        Ensure directory exists with proper permissions.
        
        Args:
            path: Directory path
            mode: Permission mode
        """
        path.mkdir(parents=True, exist_ok=True)
        path.chmod(mode)
    
    @staticmethod
    def check_port_available(port: int, host: str = '127.0.0.1') -> bool:
        """
        Check if a network port is available.
        
        Args:
            port: Port number
            host: Host address
            
        Returns:
            True if port is available
        """
        import socket
        
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.settimeout(1)
                result = s.connect_ex((host, port))
                return result != 0
        except Exception:
            return False
    
    @staticmethod
    def get_docker_version() -> Optional[Tuple[int, int, int]]:
        """
        Get Docker version.
        
        Returns:
            Version tuple (major, minor, patch) or None
        """
        try:
            result = subprocess.run(
                ['docker', 'version', '--format', '{{.Server.Version}}'],
                capture_output=True,
                text=True,
                timeout=5
            )
            if result.returncode == 0:
                version_str = result.stdout.strip()
                # Parse version like "20.10.21"
                parts = version_str.split('.')
                if len(parts) >= 3:
                    return (int(parts[0]), int(parts[1]), int(parts[2]))
        except Exception as e:
            logger.error(f"Failed to get Docker version: {e}")
        
        return None
    
    @staticmethod
    def get_kopia_version() -> Optional[str]:
        """
        Get Kopia version.
        
        Returns:
            Version string or None
        """
        try:
            result = subprocess.run(
                ['kopia', 'version'],
                capture_output=True,
                text=True,
                timeout=5
            )
            if result.returncode == 0:
                # Parse version from output
                for line in result.stdout.split('\n'):
                    if line.startswith('VERSION:'):
                        return line.split(':', 1)[1].strip()
        except Exception as e:
            logger.error(f"Failed to get Kopia version: {e}")
        
        return None

```

## File: kopia_docka/repository.py

```python
"""
Kopia repository management module.

This module handles all interactions with the Kopia backup repository,
including initialization, snapshot creation, and restoration.
"""

import json
import logging
import subprocess
from pathlib import Path
from typing import Optional, Dict, Any, List, IO

from .config import Config


logger = logging.getLogger(__name__)


class KopiaRepository:
    """
    Manages Kopia repository operations.
    
    This class provides a Python interface to Kopia commands for
    repository management, snapshot creation, and restoration.
    """
    
    def __init__(self, config: Config):
        """
        Initialize Kopia repository manager.
        
        Args:
            config: Application configuration
        """
        self.config = config
        self.repo_path = config.kopia_repository_path
        self.password = config.kopia_password
    
    def is_initialized(self) -> bool:
        """
        Check if Kopia repository is initialized.
        
        Returns:
            True if repository exists and is accessible
        """
        try:
            result = subprocess.run(
                ['kopia', 'repository', 'status', '--json'],
                env=self._get_env(),
                capture_output=True,
                text=True
            )
            return result.returncode == 0
        except FileNotFoundError:
            logger.error("Kopia binary not found")
            return False
        except Exception as e:
            logger.error(f"Failed to check repository status: {e}")
            return False
    
    def initialize(self):
        """Initialize Kopia repository."""
        logger.info(f"Initializing Kopia repository at {self.repo_path}")
        
        # Create repository directory
        self.repo_path.mkdir(parents=True, exist_ok=True)
        
        try:
            subprocess.run(
                [
                    'kopia', 'repository', 'create',
                    'filesystem',
                    '--path', str(self.repo_path),
                    '--compression', self.config.get('kopia', 'compression'),
                    '--encryption', self.config.get('kopia', 'encryption')
                ],
                env=self._get_env(),
                check=True,
                capture_output=True
            )
            logger.info("Repository initialized successfully")
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to initialize repository: {e.stderr}")
            raise
    
    def connect(self):
        """Connect to existing Kopia repository."""
        try:
            subprocess.run(
                [
                    'kopia', 'repository', 'connect',
                    'filesystem',
                    '--path', str(self.repo_path)
                ],
                env=self._get_env(),
                check=True,
                capture_output=True
            )
            logger.debug("Connected to repository")
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to connect to repository: {e.stderr}")
            raise
    
    def create_snapshot(self, path: str, tags: Optional[Dict[str, str]] = None) -> str:
        """
        Create a Kopia snapshot of a directory.
        
        Args:
            path: Path to snapshot
            tags: Optional tags to add to snapshot
            
        Returns:
            Snapshot ID
        """
        cmd = ['kopia', 'snapshot', 'create', path, '--json']
        
        # Add tags
        if tags:
            for key, value in tags.items():
                cmd.extend(['--tags', f'{key}:{value}'])
        
        try:
            result = subprocess.run(
                cmd,
                env=self._get_env(),
                capture_output=True,
                text=True,
                check=True
            )
            
            # Parse JSON output to get snapshot ID
            output = json.loads(result.stdout)
            snapshot_id = output.get('snapshotID', '')
            
            logger.info(f"Created snapshot: {snapshot_id}")
            return snapshot_id
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to create snapshot: {e.stderr}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Kopia output: {e}")
            raise
    
    def create_snapshot_from_stdin(self, 
                                  stdin: IO,
                                  path: str,
                                  tags: Optional[Dict[str, str]] = None) -> str:
        """
        Create a Kopia snapshot from stdin.
        
        Args:
            stdin: Input stream
            path: Virtual path for the snapshot
            tags: Optional tags to add to snapshot
            
        Returns:
            Snapshot ID
        """
        cmd = ['kopia', 'snapshot', 'create', '--stdin', '--stdin-file', path, '--json']
        
        # Add tags
        if tags:
            for key, value in tags.items():
                cmd.extend(['--tags', f'{key}:{value}'])
        
        try:
            result = subprocess.run(
                cmd,
                stdin=stdin,
                env=self._get_env(),
                capture_output=True,
                text=True,
                check=True
            )
            
            # Parse JSON output to get snapshot ID
            output = json.loads(result.stdout)
            snapshot_id = output.get('snapshotID', '')
            
            logger.info(f"Created snapshot from stdin: {snapshot_id}")
            return snapshot_id
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to create snapshot from stdin: {e.stderr}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Kopia output: {e}")
            raise
    
    def list_snapshots(self, tag_filter: Optional[Dict[str, str]] = None) -> List[Dict[str, Any]]:
        """
        List snapshots in repository.
        
        Args:
            tag_filter: Optional tag filter
            
        Returns:
            List of snapshot information
        """
        cmd = ['kopia', 'snapshot', 'list', '--json']
        
        # Add tag filters
        if tag_filter:
            for key, value in tag_filter.items():
                cmd.extend(['--tags', f'{key}:{value}'])
        
        try:
            result = subprocess.run(
                cmd,
                env=self._get_env(),
                capture_output=True,
                text=True,
                check=True
            )
            
            snapshots = []
            for line in result.stdout.strip().split('\n'):
                if line:
                    try:
                        snapshot = json.loads(line)
                        snapshots.append({
                            'id': snapshot.get('id', ''),
                            'path': snapshot.get('source', {}).get('path', ''),
                            'timestamp': snapshot.get('startTime', ''),
                            'tags': snapshot.get('tags', {}),
                            'size': snapshot.get('stats', {}).get('totalSize', 0)
                        })
                    except json.JSONDecodeError:
                        continue
            
            return snapshots
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to list snapshots: {e.stderr}")
            return []
    
    def restore_snapshot(self, snapshot_id: str, target_path: str):
        """
        Restore a snapshot to a directory.
        
        Args:
            snapshot_id: Snapshot ID to restore
            target_path: Target directory for restoration
        """
        logger.info(f"Restoring snapshot {snapshot_id} to {target_path}")
        
        try:
            subprocess.run(
                [
                    'kopia', 'snapshot', 'restore',
                    snapshot_id,
                    target_path
                ],
                env=self._get_env(),
                check=True,
                capture_output=True
            )
            logger.info(f"Snapshot restored to {target_path}")
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to restore snapshot: {e.stderr}")
            raise
    
    def verify_snapshot(self, snapshot_id: str) -> bool:
        """
        Verify snapshot integrity.
        
        Args:
            snapshot_id: Snapshot ID to verify
            
        Returns:
            True if snapshot is valid
        """
        try:
            result = subprocess.run(
                ['kopia', 'snapshot', 'verify', '--verify-files-percent=10', snapshot_id],
                env=self._get_env(),
                capture_output=True,
                text=True
            )
            return result.returncode == 0
        except subprocess.CalledProcessError:
            return False
    
    def delete_snapshot(self, snapshot_id: str):
        """
        Delete a snapshot.
        
        Args:
            snapshot_id: Snapshot ID to delete
        """
        try:
            subprocess.run(
                ['kopia', 'snapshot', 'delete', snapshot_id, '--delete'],
                env=self._get_env(),
                check=True,
                capture_output=True
            )
            logger.info(f"Deleted snapshot: {snapshot_id}")
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to delete snapshot: {e.stderr}")
            raise
    
    def list_backup_units(self) -> List[Dict[str, Any]]:
        """
        List all backup units in repository.
        
        Returns:
            List of backup unit information
        """
        snapshots = self.list_snapshots(tag_filter={'type': 'recipe'})
        
        units = {}
        for snap in snapshots:
            unit_name = snap['tags'].get('unit')
            if unit_name:
                if unit_name not in units or snap['timestamp'] > units[unit_name]['timestamp']:
                    units[unit_name] = {
                        'name': unit_name,
                        'timestamp': snap['timestamp'],
                        'snapshot_id': snap['id']
                    }
        
        return list(units.values())
    
    def maintenance_run(self):
        """Run Kopia maintenance."""
        logger.info("Running repository maintenance")
        
        try:
            subprocess.run(
                ['kopia', 'maintenance', 'run', '--full'],
                env=self._get_env(),
                check=True,
                capture_output=True
            )
            logger.info("Maintenance completed")
        except subprocess.CalledProcessError as e:
            logger.error(f"Maintenance failed: {e.stderr}")
    
    def _get_env(self) -> Dict[str, str]:
        """
        Get environment variables for Kopia commands.
        
        Returns:
            Dictionary of environment variables
        """
        import os
        env = os.environ.copy()
        env['KOPIA_PASSWORD'] = self.password
        
        cache_dir = self.config.get('kopia', 'cache_directory')
        if cache_dir:
            env['KOPIA_CACHE_DIRECTORY'] = cache_dir
        
        return env
kopia-docka/
├── kopia_docka/
│   ├── __init__.py
│   ├── __main__.py
│   ├── config.py
│   ├── constants.py
│   ├── types.py
│   ├── discovery.py
│   ├── backup.py
│   ├── restore.py
│   ├── repository.py
│   ├── system_utils.py
│   └── dry_run.py
├── setup.py
├── requirements.txt
├── config.template.ini
└── README.md
```

## File: kopia_docka/__init__.py

```python
"""
Kopia-Docka: A robust backup solution for Docker environments using Kopia.

This package provides a modular command-line tool for backing up and restoring
Docker containers and their associated data with minimal downtime and maximum
reliability.
"""

__version__ = "1.0.0"
__author__ = "Kopia-Docka Development Team"

from .types import BackupUnit, ContainerInfo, VolumeInfo
from .config import Config
from .discovery import DockerDiscovery
from .backup import BackupManager
from .restore import RestoreManager
from .repository import KopiaRepository

__all__ = [
    'BackupUnit',
    'ContainerInfo',
    'VolumeInfo',
    'Config',
    'DockerDiscovery',
    'BackupManager',
    'RestoreManager',
    'KopiaRepository',
]
```

## File: kopia_docka/__main__.py

```python
#!/usr/bin/env python3
"""
Main entry point for the Kopia-Docka command-line tool.

This module handles command-line argument parsing and delegates to appropriate
subcommands for backup, restore, and other operations.
"""

import sys
import argparse
import logging
from pathlib import Path

from .config import Config, create_default_config
from .discovery import DockerDiscovery
from .backup import BackupManager
from .restore import RestoreManager
from .repository import KopiaRepository
from .system_utils import SystemUtils
from .dry_run import DryRunReport
from .constants import DEFAULT_CONFIG_PATHS


def setup_logging(verbose: bool = False):
    """
    Configure logging for the application.
    
    Args:
        verbose: Enable verbose logging if True
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


def cmd_backup(args, config):
    """
    Execute backup command.
    
    Args:
        args: Parsed command-line arguments
        config: Configuration object
    """
    discovery = DockerDiscovery()
    backup_manager = BackupManager(config)
    
    if args.dry_run:
        report = DryRunReport(config)
        units = discovery.discover_backup_units()
        report.generate(units)
        return
    
    units = discovery.discover_backup_units()
    
    if args.unit:
        units = [u for u in units if u.name == args.unit]
        if not units:
            logging.error(f"Backup unit '{args.unit}' not found")
            sys.exit(1)
    
    for unit in units:
        backup_manager.backup_unit(unit)


def cmd_restore(args, config):
    """
    Execute restore command.
    
    Args:
        args: Parsed command-line arguments
        config: Configuration object
    """
    restore_manager = RestoreManager(config)
    restore_manager.interactive_restore()


def cmd_list(args, config):
    """
    List backups command.
    
    Args:
        args: Parsed command-line arguments
        config: Configuration object
    """
    repo = KopiaRepository(config)
    
    if args.units:
        units = repo.list_backup_units()
        for unit in units:
            print(f"Unit: {unit['name']} - Last backup: {unit['timestamp']}")
    else:
        snapshots = repo.list_snapshots()
        for snap in snapshots:
            print(f"Snapshot: {snap['id']} - {snap['path']} - {snap['timestamp']}")


def cmd_check(args, config):
    """
    Check system requirements.
    
    Args:
        args: Parsed command-line arguments
        config: Configuration object
    """
    utils = SystemUtils()
    
    print("System Check Report")
    print("=" * 50)
    
    # Check Docker
    if utils.check_docker():
        print("✓ Docker is installed and running")
    else:
        print("✗ Docker is not available")
    
    # Check Kopia
    if utils.check_kopia():
        print("✓ Kopia is installed")
    else:
        print("✗ Kopia is not installed")
    
    # Check system resources
    ram_gb = utils.get_available_ram()
    print(f"✓ Available RAM: {ram_gb:.2f} GB")
    print(f"✓ Recommended workers: {utils.get_optimal_workers()}")
    
    # Check repository
    try:
        repo = KopiaRepository(config)
        if repo.is_initialized():
            print("✓ Kopia repository is initialized")
        else:
            print("✗ Kopia repository not initialized")
    except Exception as e:
        print(f"✗ Repository check failed: {e}")


def cmd_config(args, config):
    """
    Configuration management command.
    
    Args:
        args: Parsed command-line arguments
        config: Configuration object
    """
    if args.show:
        config.display()
    elif args.init:
        create_default_config(force=True)
        print("Configuration file created successfully")
    elif args.edit:
        import subprocess
        import os
        editor = os.environ.get('EDITOR', 'nano')
        subprocess.call([editor, str(config.config_file)])


def cmd_install(args, config):
    """
    Install and initialize Kopia repository.
    
    Args:
        args: Parsed command-line arguments
        config: Configuration object
    """
    repo = KopiaRepository(config)
    
    if repo.is_initialized():
        print("Repository already initialized")
        return
    
    repo.initialize()
    print("Kopia repository initialized successfully")


def main():
    """Main entry point for the application."""
    parser = argparse.ArgumentParser(
        prog='kopia-docka',
        description='Robust backup solution for Docker environments using Kopia'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose output'
    )
    
    parser.add_argument(
        '-c', '--config',
        type=Path,
        help='Path to configuration file'
    )
    
    subparsers = parser.add_subparsers(
        title='Commands',
        dest='command',
        help='Available commands'
    )
    
    # Backup command
    backup_parser = subparsers.add_parser(
        'backup',
        help='Backup Docker containers and volumes'
    )
    backup_parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Simulate backup without making changes'
    )
    backup_parser.add_argument(
        '--unit',
        type=str,
        help='Backup specific unit only'
    )
    
    # Restore command
    restore_parser = subparsers.add_parser(
        'restore',
        help='Restore Docker containers and volumes'
    )
    
    # List command
    list_parser = subparsers.add_parser(
        'list',
        help='List available backups'
    )
    list_parser.add_argument(
        '--units',
        action='store_true',
        help='List backup units instead of snapshots'
    )
    
    # Check command
    check_parser = subparsers.add_parser(
        'check',
        help='Check system requirements and status'
    )
    
    # Config command
    config_parser = subparsers.add_parser(
        'config',
        help='Configuration management'
    )
    config_parser.add_argument(
        '--show',
        action='store_true',
        help='Show current configuration'
    )
    config_parser.add_argument(
        '--init',
        action='store_true',
        help='Initialize configuration file'
    )
    config_parser.add_argument(
        '--edit',
        action='store_true',
        help='Edit configuration file'
    )
    
    # Install command
    install_parser = subparsers.add_parser(
        'install',
        help='Initialize Kopia repository'
    )
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(0)
    
    setup_logging(args.verbose)
    
    # Load configuration
    config_path = args.config if hasattr(args, 'config') and args.config else None
    config = Config(config_path)
    
    # Execute command
    commands = {
        'backup': cmd_backup,
        'restore': cmd_restore,
        'list': cmd_list,
        'check': cmd_check,
        'config': cmd_config,
        'install': cmd_install,
    }
    
    try:
        commands[args.command](args, config)
    except KeyboardInterrupt:
        logging.info("Operation cancelled by user")
        sys.exit(130)
    except Exception as e:
        logging.error(f"Command failed: {e}")
        if args.verbose:
            logging.exception("Full traceback:")
        sys.exit(1)


if __name__ == '__main__':
    main()
```

## File: kopia_docka/constants.py

```python
"""
Constants used throughout the Kopia-Docka application.

This module defines all constant values used across different modules
to ensure consistency and ease of maintenance.
"""

import os
from pathlib import Path

# Version information
VERSION = "1.0.0"

# Default paths
DEFAULT_CONFIG_PATHS = {
    'root': Path('/etc/kopia-docka.conf'),
    'user': Path.home() / '.config' / 'kopia-docker' / 'config.conf'
}

# Docker labels
DOCKER_COMPOSE_PROJECT_LABEL = 'com.docker.compose.project'
DOCKER_COMPOSE_CONFIG_LABEL = 'com.docker.compose.project.config_files'
DOCKER_COMPOSE_SERVICE_LABEL = 'com.docker.compose.service'

# Backup paths
DEFAULT_BACKUP_BASE = '/backup/kopia-docka'
RECIPE_BACKUP_DIR = 'recipes'
VOLUME_BACKUP_DIR = 'volumes'
DATABASE_BACKUP_DIR = 'databases'

# Database detection patterns
DATABASE_IMAGES = {
    'postgres': {
        'patterns': ['postgres:', 'postgresql:', 'postgis/'],
        'dump_command': 'pg_dumpall -U {user}',
        'env_user': 'POSTGRES_USER',
        'default_user': 'postgres'
    },
    'mysql': {
        'patterns': ['mysql:', 'mariadb:', 'percona:'],
        'dump_command': 'mysqldump --all-databases -u{user} -p{password}',
        'env_user': 'MYSQL_USER',
        'env_password': 'MYSQL_PASSWORD',
        'env_root_password': 'MYSQL_ROOT_PASSWORD',
        'default_user': 'root'
    },
    'mongodb': {
        'patterns': ['mongo:', 'mongodb:'],
        'dump_command': 'mongodump --archive',
        'env_user': 'MONGO_INITDB_ROOT_USERNAME',
        'env_password': 'MONGO_INITDB_ROOT_PASSWORD'
    },
    'redis': {
        'patterns': ['redis:', 'redis/'],
        'dump_command': 'redis-cli --rdb -',
        'env_password': 'REDIS_PASSWORD'
    }
}

# System thresholds
RAM_WORKER_THRESHOLDS = [
    (2, 1),    # <= 2GB: 1 worker
    (4, 2),    # <= 4GB: 2 workers
    (8, 4),    # <= 8GB: 4 workers
    (16, 8),   # <= 16GB: 8 workers
    (float('inf'), 12)  # > 16GB: 12 workers
]

# Timeouts (in seconds)
CONTAINER_STOP_TIMEOUT = 30
CONTAINER_START_TIMEOUT = 60
BACKUP_OPERATION_TIMEOUT = 3600  # 1 hour

# Kopia settings
KOPIA_COMPRESSION = 'zstd'
KOPIA_ENCRYPTION = 'AES256-GCM-HMAC-SHA256'

# Logging
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

# File patterns to exclude from backup
EXCLUDE_PATTERNS = [
    '*.tmp',
    '*.temp',
    '*.log',
    '.git/',
    '__pycache__/',
    '*.pyc'
]
```

## File: kopia_docka/types.py

```python
"""
Type definitions and data structures for Kopia-Docka.

This module defines the core data structures used throughout the application
to represent containers, volumes, and backup units.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any
from datetime import datetime
from pathlib import Path


@dataclass
class VolumeInfo:
    """
    Represents information about a Docker volume.
    
    Attributes:
        name: Volume name
        driver: Volume driver (e.g., 'local')
        mountpoint: Path where volume is mounted on host
        labels: Volume labels
        size_bytes: Estimated size in bytes (optional)
        container_ids: List of container IDs using this volume
    """
    name: str
    driver: str
    mountpoint: str
    labels: Dict[str, str] = field(default_factory=dict)
    size_bytes: Optional[int] = None
    container_ids: List[str] = field(default_factory=list)
    
    def __repr__(self) -> str:
        """String representation of VolumeInfo."""
        return f"VolumeInfo(name={self.name}, driver={self.driver})"


@dataclass
class ContainerInfo:
    """
    Represents information about a Docker container.
    
    Attributes:
        id: Container ID
        name: Container name
        image: Image name
        status: Container status
        labels: Container labels
        environment: Environment variables
        volumes: List of volume names used by container
        compose_file: Path to docker-compose file if applicable
        inspect_data: Full docker inspect output
        database_type: Type of database if detected (postgres, mysql, etc.)
    """
    id: str
    name: str
    image: str
    status: str
    labels: Dict[str, str] = field(default_factory=dict)
    environment: Dict[str, str] = field(default_factory=dict)
    volumes: List[str] = field(default_factory=list)
    compose_file: Optional[Path] = None
    inspect_data: Optional[Dict[str, Any]] = None
    database_type: Optional[str] = None
    
    def __repr__(self) -> str:
        """String representation of ContainerInfo."""
        return f"ContainerInfo(id={self.id[:12]}, name={self.name})"
    
    @property
    def is_running(self) -> bool:
        """Check if container is running."""
        return self.status.lower().startswith('running')
    
    @property
    def is_database(self) -> bool:
        """Check if container is a database."""
        return self.database_type is not None
    
    @property
    def stack_name(self) -> Optional[str]:
        """Get stack name from labels if available."""
        from .constants import DOCKER_COMPOSE_PROJECT_LABEL
        return self.labels.get(DOCKER_COMPOSE_PROJECT_LABEL)


@dataclass
class BackupUnit:
    """
    Represents a logical backup unit (stack or standalone container).
    
    Attributes:
        name: Unit name
        type: Unit type ('stack' or 'standalone')
        containers: List of containers in this unit
        volumes: List of volumes used by this unit
        compose_file: Path to docker-compose file for stacks
        created_at: Timestamp when unit was discovered
        priority: Backup priority (lower = higher priority)
    """
    name: str
    type: str  # 'stack' or 'standalone'
    containers: List[ContainerInfo] = field(default_factory=list)
    volumes: List[VolumeInfo] = field(default_factory=list)
    compose_file: Optional[Path] = None
    created_at: datetime = field(default_factory=datetime.now)
    priority: int = 100
    
    def __repr__(self) -> str:
        """String representation of BackupUnit."""
        return f"BackupUnit(name={self.name}, type={self.type}, containers={len(self.containers)})"
    
    @property
    def total_volume_size(self) -> int:
        """Calculate total size of all volumes."""
        return sum(v.size_bytes or 0 for v in self.volumes)
    
    @property
    def has_databases(self) -> bool:
        """Check if unit contains database containers."""
        return any(c.is_database for c in self.containers)
    
    @property
    def running_containers(self) -> List[ContainerInfo]:
        """Get list of running containers."""
        return [c for c in self.containers if c.is_running]
    
    def get_database_containers(self) -> List[ContainerInfo]:
        """Get all database containers in this unit."""
        return [c for c in self.containers if c.is_database]


@dataclass
class BackupMetadata:
    """
    Metadata for a backup operation.
    
    Attributes:
        unit_name: Name of the backup unit
        timestamp: When backup was created
        duration_seconds: How long backup took
        volumes_backed_up: Number of volumes backed up
        databases_backed_up: Number of databases backed up
        total_size_bytes: Total backup size
        kopia_snapshot_ids: List of Kopia snapshot IDs created
        success: Whether backup completed successfully
        error_message: Error message if backup failed
    """
    unit_name: str
    timestamp: datetime
    duration_seconds: float
    volumes_backed_up: int = 0
    databases_backed_up: int = 0
    total_size_bytes: int = 0
    kopia_snapshot_ids: List[str] = field(default_factory=list)
    success: bool = True
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            'unit_name': self.unit_name,
            'timestamp': self.timestamp.isoformat(),
            'duration_seconds': self.duration_seconds,
            'volumes_backed_up': self.volumes_backed_up,
            'databases_backed_up': self.databases_backed_up,
            'total_size_bytes': self.total_size_bytes,
            'kopia_snapshot_ids': self.kopia_snapshot_ids,
            'success': self.success,
            'error_message': self.error_message
        }


@dataclass
class RestorePoint:
    """
    Represents a point in time that can be restored.
    
    Attributes:
        unit_name: Name of the backup unit
        timestamp: When backup was created
        recipe_snapshot: Kopia snapshot ID for recipes
        volume_snapshots: Map of volume name to snapshot ID
        database_snapshots: Map of container name to snapshot ID
        metadata: Additional metadata about the restore point
    """
    unit_name: str
    timestamp: datetime
    recipe_snapshot: str
    volume_snapshots: Dict[str, str] = field(default_factory=dict)
    database_snapshots: Dict[str, str] = field(default_factory=dict)
    metadata: Optional[BackupMetadata] = None
    
    def __repr__(self) -> str:
        """String representation of RestorePoint."""
        return f"RestorePoint(unit={self.unit_name}, time={self.timestamp})"
```

## File: kopia_docka/config.py

```python
"""
Configuration management for Kopia-Docka.

This module handles reading, writing, and validating configuration files,
as well as creating default configurations when needed.
"""

import configparser
import logging
import secrets
import string
from pathlib import Path
from typing import Optional, Dict, Any
import os

from .constants import DEFAULT_CONFIG_PATHS, DEFAULT_BACKUP_BASE


logger = logging.getLogger(__name__)


class Config:
    """
    Manages application configuration.
    
    This class handles loading configuration from INI files, providing
    default values, and validating settings.
    
    Attributes:
        config_file: Path to the configuration file
        _config: ConfigParser instance
        _defaults: Default configuration values
    """
    
    def __init__(self, config_path: Optional[Path] = None):
        """
        Initialize configuration.
        
        Args:
            config_path: Optional path to configuration file.
                        If not provided, searches standard locations.
        """
        self._defaults = self._get_defaults()
        self._config = configparser.ConfigParser()
        
        # Find or create configuration file
        self.config_file = self._find_config_file(config_path)
        if not self.config_file.exists():
            logger.info(f"Creating default configuration at {self.config_file}")
            create_default_config(self.config_file)
        
        self._load_config()
    
    def _get_defaults(self) -> Dict[str, Dict[str, Any]]:
        """
        Get default configuration values.
        
        Returns:
            Dictionary of default configuration sections and values
        """
        return {
            'kopia': {
                'repository_path': '/backup/kopia-repository',
                'password': generate_secure_password(),
                'compression': 'zstd',
                'encryption': 'AES256-GCM-HMAC-SHA256',
                'cache_directory': '/var/cache/kopia-docka'
            },
            'backup': {
                'base_path': DEFAULT_BACKUP_BASE,
                'parallel_workers': 'auto',
                'stop_timeout': 30,
                'start_timeout': 60,
                'exclude_patterns': '*.tmp,*.temp,*.log,.git/,__pycache__/',
                'database_backup': 'true',
                'verify_after_backup': 'false'
            },
            'docker': {
                'socket': '/var/run/docker.sock',
                'compose_timeout': 300,
                'prune_stopped_containers': 'false'
            },
            'logging': {
                'level': 'INFO',
                'file': '/var/log/kopia-docka.log',
                'max_size_mb': 100,
                'backup_count': 5
            },
            'schedule': {
                'enabled': 'false',
                'daily_at': '02:00',
                'weekly_on': 'sunday',
                'monthly_on': '1',
                'retention_daily': 7,
                'retention_weekly': 4,
                'retention_monthly': 12
            }
        }
    
    def _find_config_file(self, config_path: Optional[Path] = None) -> Path:
        """
        Find or determine configuration file path.
        
        Args:
            config_path: Explicitly provided configuration path
            
        Returns:
            Path to configuration file
        """
        if config_path and config_path.exists():
            return config_path
        
        # Check standard locations
        if os.geteuid() == 0:  # Running as root
            return DEFAULT_CONFIG_PATHS['root']
        else:
            path = DEFAULT_CONFIG_PATHS['user']
            path.parent.mkdir(parents=True, exist_ok=True)
            return path
    
    def _load_config(self):
        """Load configuration from file."""
        try:
            self._config.read(self.config_file)
            logger.info(f"Configuration loaded from {self.config_file}")
        except Exception as e:
            logger.error(f"Failed to load configuration: {e}")
            raise
    
    def get(self, section: str, option: str, fallback: Any = None) -> Any:
        """
        Get configuration value.
        
        Args:
            section: Configuration section
            option: Configuration option
            fallback: Fallback value if not found
            
        Returns:
            Configuration value or fallback
        """
        try:
            return self._config.get(section, option)
        except (configparser.NoSectionError, configparser.NoOptionError):
            # Try to get from defaults
            if section in self._defaults and option in self._defaults[section]:
                return self._defaults[section][option]
            return fallback
    
    def getint(self, section: str, option: str, fallback: int = 0) -> int:
        """
        Get integer configuration value.
        
        Args:
            section: Configuration section
            option: Configuration option
            fallback: Fallback value if not found
            
        Returns:
            Integer configuration value or fallback
        """
        value = self.get(section, option, fallback)
        if isinstance(value, str):
            if value.lower() == 'auto':
                return -1  # Special value for auto
            try:
                return int(value)
            except ValueError:
                return fallback
        return int(value)
    
    def getboolean(self, section: str, option: str, fallback: bool = False) -> bool:
        """
        Get boolean configuration value.
        
        Args:
            section: Configuration section
            option: Configuration option
            fallback: Fallback value if not found
            
        Returns:
            Boolean configuration value or fallback
        """
        value = self.get(section, option, str(fallback))
        if isinstance(value, bool):
            return value
        return value.lower() in ('true', 'yes', '1', 'on')
    
    def getlist(self, section: str, option: str, fallback: list = None) -> list:
        """
        Get list configuration value (comma-separated).
        
        Args:
            section: Configuration section
            option: Configuration option
            fallback: Fallback value if not found
            
        Returns:
            List of configuration values or fallback
        """
        value = self.get(section, option)
        if value:
            return [item.strip() for item in value.split(',')]
        return fallback or []
    
    def set(self, section: str, option: str, value: Any):
        """
        Set configuration value.
        
        Args:
            section: Configuration section
            option: Configuration option
            value: Value to set
        """
        if not self._config.has_section(section):
            self._config.add_section(section)
        self._config.set(section, option, str(value))
    
    def save(self):
        """Save configuration to file."""
        with open(self.config_file, 'w') as f:
            self._config.write(f)
        logger.info(f"Configuration saved to {self.config_file}")
    
    def display(self):
        """Display current configuration (with sensitive values masked)."""
        print(f"Configuration file: {self.config_file}")
        print("=" * 60)
        
        for section in self._config.sections():
            print(f"\n[{section}]")
            for option, value in self._config.items(section):
                # Mask sensitive values
                if 'password' in option.lower() or 'token' in option.lower():
                    value = '***MASKED***'
                print(f"  {option} = {value}")
    
    @property
    def kopia_repository_path(self) -> Path:
        """Get Kopia repository path."""
        return Path(self.get('kopia', 'repository_path'))
    
    @property
    def kopia_password(self) -> str:
        """Get Kopia password."""
        return self.get('kopia', 'password')
    
    @property
    def backup_base_path(self) -> Path:
        """Get backup base path."""
        return Path(self.get('backup', 'base_path'))
    
    @property
    def parallel_workers(self) -> int:
        """Get number of parallel workers."""
        workers = self.getint('backup', 'parallel_workers', -1)
        if workers == -1:  # auto
            from .system_utils import SystemUtils
            return SystemUtils().get_optimal_workers()
        return workers
    
    @property
    def docker_socket(self) -> str:
        """Get Docker socket path."""
        return self.get('docker', 'socket', '/var/run/docker.sock')


def generate_secure_password(length: int = 32) -> str:
    """
    Generate a cryptographically secure password.
    
    Args:
        length: Password length
        
    Returns:
        Secure random password
    """
    alphabet = string.ascii_letters + string.digits + string.punctuation
    return ''.join(secrets.choice(alphabet) for _ in range(length))


def create_default_config(path: Optional[Path] = None, force: bool = False):
    """
    Create default configuration file.
    
    Args:
        path: Path where to create config file
        force: Overwrite existing file if True
    """
    if path is None:
        if os.geteuid() == 0:
            path = DEFAULT_CONFIG_PATHS['root']
        else:
            path = DEFAULT_CONFIG_PATHS['user']
    
    if path.exists() and not force:
        logger.warning(f"Configuration file already exists at {path}")
        return
    
    # Ensure directory exists
    path.parent.mkdir(parents=True, exist_ok=True)
    
    # Copy template
    template_path = Path(__file__).parent.parent / 'config.template.ini'
    if template_path.exists():
        import shutil
        shutil.copy(template_path, path)
    else:
        # Generate from defaults
        config = Config(path)
        config.save()
    
    # Set secure permissions
    path.chmod(0o600)
    logger.info(f"Default configuration created at {path}")
```

## File: kopia_docka/discovery.py

```python
"""
Docker discovery module for Kopia-Docka.

This module handles discovering Docker containers, volumes, and grouping
them into logical backup units (stacks or standalone containers).
"""

import json
import logging
import subprocess
from typing import List, Dict, Optional, Any
from pathlib import Path

from .types import BackupUnit, ContainerInfo, VolumeInfo
from .constants import (
    DOCKER_COMPOSE_PROJECT_LABEL,
    DOCKER_COMPOSE_CONFIG_LABEL,
    DOCKER_COMPOSE_SERVICE_LABEL,
    DATABASE_IMAGES
)


logger = logging.getLogger(__name__)


class DockerDiscovery:
    """
    Discovers Docker containers and volumes, grouping them into backup units.
    
    This class interfaces with the Docker daemon to discover running containers,
    their volumes, and groups them into logical units for backup.
    """
    
    def __init__(self, docker_socket: str = '/var/run/docker.sock'):
        """
        Initialize Docker discovery.
        
        Args:
            docker_socket: Path to Docker socket
        """
        self.docker_socket = docker_socket
        self._validate_docker_access()
    
    def _validate_docker_access(self):
        """Validate Docker daemon accessibility."""
        try:
            result = subprocess.run(
                ['docker', 'version'],
                capture_output=True,
                text=True,
                timeout=5
            )
            if result.returncode != 0:
                raise RuntimeError(f"Docker daemon not accessible: {result.stderr}")
        except Exception as e:
            logger.error(f"Failed to access Docker: {e}")
            raise
    
    def _run_docker_command(self, args: List[str]) -> str:
        """
        Run a Docker command and return output.
        
        Args:
            args: Docker command arguments
            
        Returns:
            Command output as string
        """
        cmd = ['docker'] + args
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )
            return result.stdout
        except subprocess.CalledProcessError as e:
            logger.error(f"Docker command failed: {' '.join(cmd)}")
            logger.error(f"Error: {e.stderr}")
            raise
    
    def discover_backup_units(self) -> List[BackupUnit]:
        """
        Discover all backup units.
        
        Returns:
            List of discovered backup units
        """
        logger.info("Starting Docker discovery...")
        
        containers = self._discover_containers()
        volumes = self._discover_volumes()
        
        # Group containers into units
        units = self._group_into_units(containers, volumes)
        
        logger.info(f"Discovered {len(units)} backup units")
        for unit in units:
            logger.info(f"  - {unit.name}: {len(unit.containers)} containers, "
                       f"{len(unit.volumes)} volumes")
        
        return units
    
    def _discover_containers(self) -> List[ContainerInfo]:
        """
        Discover all running containers.
        
        Returns:
            List of container information
        """
        # Get container IDs
        output = self._run_docker_command(['ps', '-q'])
        if not output.strip():
            logger.warning("No running containers found")
            return []
        
        container_ids = output.strip().split('\n')
        containers = []
        
        for container_id in container_ids:
            try:
                # Get detailed container information
                inspect_output = self._run_docker_command(['inspect', container_id])
                inspect_data = json.loads(inspect_output)[0]
                
                container = self._parse_container_info(inspect_data)
                containers.append(container)
                
            except Exception as e:
                logger.error(f"Failed to inspect container {container_id}: {e}")
                continue
        
        return containers
    
    def _parse_container_info(self, inspect_data: Dict[str, Any]) -> ContainerInfo:
        """
        Parse container information from Docker inspect output.
        
        Args:
            inspect_data: Docker inspect JSON data
            
        Returns:
            ContainerInfo object
        """
        # Extract basic information
        container_id = inspect_data['Id']
        name = inspect_data['Name'].lstrip('/')
        image = inspect_data['Config']['Image']
        status = inspect_data['State']['Status']
        labels = inspect_data['Config'].get('Labels', {}) or {}
        
        # Extract environment variables
        env_list = inspect_data['Config'].get('Env', [])
        environment = {}
        for env_str in env_list:
            if '=' in env_str:
                key, value = env_str.split('=', 1)
                environment[key] = value
        
        # Extract volumes
        volumes = []
        mounts = inspect_data.get('Mounts', [])
        for mount in mounts:
            if mount['Type'] == 'volume':
                volumes.append(mount['Name'])
        
        # Check for compose file
        compose_file = None
        if DOCKER_COMPOSE_CONFIG_LABEL in labels:
            compose_files = labels[DOCKER_COMPOSE_CONFIG_LABEL]
            if compose_files:
                # Take the first file if multiple
                compose_file = Path(compose_files.split(',')[0])
        
        # Detect database type
        database_type = self._detect_database_type(image)
        
        return ContainerInfo(
            id=container_id,
            name=name,
            image=image,
            status=status,
            labels=labels,
            environment=environment,
            volumes=volumes,
            compose_file=compose_file,
            inspect_data=inspect_data,
            database_type=database_type
        )
    
    def _detect_database_type(self, image: str) -> Optional[str]:
        """
        Detect if container is a database based on image name.
        
        Args:
            image: Docker image name
            
        Returns:
            Database type or None
        """
        image_lower = image.lower()
        
        for db_type, db_info in DATABASE_IMAGES.items():
            for pattern in db_info['patterns']:
                if pattern in image_lower:
                    return db_type
        
        return None
    
    def _discover_volumes(self) -> List[VolumeInfo]:
        """
        Discover all Docker volumes.
        
        Returns:
            List of volume information
        """
        output = self._run_docker_command(['volume', 'ls', '--format', 'json'])
        if not output.strip():
            return []
        
        volumes = []
        for line in output.strip().split('\n'):
            try:
                volume_data = json.loads(line)
                volume_name = volume_data['Name']
                
                # Get detailed volume information
                inspect_output = self._run_docker_command(['volume', 'inspect', volume_name])
                inspect_data = json.loads(inspect_output)[0]
                
                volume = VolumeInfo(
                    name=inspect_data['Name'],
                    driver=inspect_data['Driver'],
                    mountpoint=inspect_data['Mountpoint'],
                    labels=inspect_data.get('Labels', {}) or {}
                )
                
                # Try to estimate size (this is approximate)
                volume.size_bytes = self._estimate_volume_size(volume.mountpoint)
                
                volumes.append(volume)
                
            except Exception as e:
                logger.error(f"Failed to inspect volume: {e}")
                continue
        
        return volumes
    
    def _estimate_volume_size(self, mountpoint: str) -> Optional[int]:
        """
        Estimate volume size using du command.
        
        Args:
            mountpoint: Volume mount point
            
        Returns:
            Size in bytes or None if cannot determine
        """
        try:
            result = subprocess.run(
                ['du', '-sb', mountpoint],
                capture_output=True,
                text=True,
                timeout=30
            )
            if result.returncode == 0:
                size_str = result.stdout.split('\t')[0]
                return int(size_str)
        except Exception as e:
            logger.debug(f"Could not estimate volume size: {e}")
        
        return None
    
    def _group_into_units(self, 
                         containers: List[ContainerInfo],
                         volumes: List[VolumeInfo]) -> List[BackupUnit]:
        """
        Group containers and volumes into backup units.
        
        Args:
            containers: List of discovered containers
            volumes: List of discovered volumes
            
        Returns:
            List of backup units
        """
        units = []
        processed_containers = set()
        
        # Create a mapping of volume names to volume info
        volume_map = {v.name: v for v in volumes}
        
        # Group by Docker Compose stacks
        stacks = {}
        for container in containers:
            stack_name = container.stack_name
            if stack_name:
                if stack_name not in stacks:
                    stacks[stack_name] = []
                stacks[stack_name].append(container)
                processed_containers.add(container.id)
        
        # Create units for stacks
        for stack_name, stack_containers in stacks.items():
            unit = BackupUnit(
                name=stack_name,
                type='stack',
                containers=stack_containers
            )
            
            # Find compose file
            for container in stack_containers:
                if container.compose_file:
                    unit.compose_file = container.compose_file
                    break
            
            # Collect volumes used by stack
            unit_volume_names = set()
            for container in stack_containers:
                unit_volume_names.update(container.volumes)
            
            unit.volumes = [volume_map[vn] for vn in unit_volume_names 
                          if vn in volume_map]
            
            # Update volume container associations
            for volume in unit.volumes:
                for container in stack_containers:
                    if volume.name in container.volumes:
                        volume.container_ids.append(container.id)
            
            units.append(unit)
        
        # Create units for standalone containers
        for container in containers:
            if container.id not in processed_containers:
                unit = BackupUnit(
                    name=container.name,
                    type='standalone',
                    containers=[container]
                )
                
                # Collect volumes
                unit.volumes = [volume_map[vn] for vn in container.volumes 
                              if vn in volume_map]
                
                # Update volume container associations
                for volume in unit.volumes:
                    volume.container_ids.append(container.id)
                
                units.append(unit)
        
        # Sort units by priority (databases first, then by name)
        units.sort(key=lambda u: (
            0 if u.has_databases else 1,
            u.name
        ))
        
        return units
```

## File: kopia_docka/backup.py

```python
"""
Backup management module for Kopia-Docka.

This module handles the actual backup operations, including stopping containers,
backing up volumes and databases, and restarting containers.
"""

import json
import logging
import subprocess
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any

from .types import BackupUnit, ContainerInfo, VolumeInfo, BackupMetadata
from .config import Config
from .repository import KopiaRepository
from .constants import (
    CONTAINER_STOP_TIMEOUT,
    CONTAINER_START_TIMEOUT,
    DATABASE_IMAGES,
    RECIPE_BACKUP_DIR,
    VOLUME_BACKUP_DIR,
    DATABASE_BACKUP_DIR
)


logger = logging.getLogger(__name__)


class BackupManager:
    """
    Manages backup operations for Docker backup units.
    
    This class orchestrates the backup process, including stopping containers,
    backing up data, and restarting containers.
    """
    
    def __init__(self, config: Config):
        """
        Initialize backup manager.
        
        Args:
            config: Application configuration
        """
        self.config = config
        self.repo = KopiaRepository(config)
        self.max_workers = config.parallel_workers
    
    def backup_unit(self, unit: BackupUnit) -> BackupMetadata:
        """
        Perform complete backup of a backup unit.
        
        This implements the sequential "Cold Backup" strategy:
        1. Stop containers
        2. Backup recipes (compose files, inspect data)
        3. Backup volumes
        4. Backup databases
        5. Start containers
        
        Args:
            unit: Backup unit to backup
            
        Returns:
            Backup metadata with results
        """
        logger.info(f"Starting backup of unit: {unit.name}")
        start_time = time.time()
        metadata = BackupMetadata(
            unit_name=unit.name,
            timestamp=datetime.now(),
            duration_seconds=0
        )
        
        try:
            # Step 1: Stop containers
            logger.info(f"Stopping {len(unit.containers)} containers...")
            self._stop_containers(unit.containers)
            
            # Step 2: Backup recipes
            logger.info("Backing up recipes...")
            recipe_snapshot = self._backup_recipes(unit)
            if recipe_snapshot:
                metadata.kopia_snapshot_ids.append(recipe_snapshot)
            
            # Step 3 & 4: Backup volumes and databases in parallel
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = []
                
                # Submit volume backup tasks
                for volume in unit.volumes:
                    future = executor.submit(self._backup_volume, volume, unit)
                    futures.append(('volume', volume.name, future))
                
                # Submit database backup tasks
                for container in unit.get_database_containers():
                    future = executor.submit(self._backup_database, container, unit)
                    futures.append(('database', container.name, future))
                
                # Wait for all backups to complete
                for backup_type, name, future in futures:
                    try:
                        snapshot_id = future.result(timeout=3600)
                        if snapshot_id:
                            metadata.kopia_snapshot_ids.append(snapshot_id)
                            if backup_type == 'volume':
                                metadata.volumes_backed_up += 1
                            else:
                                metadata.databases_backed_up += 1
                            logger.info(f"Backed up {backup_type}: {name}")
                    except Exception as e:
                        logger.error(f"Failed to backup {backup_type} {name}: {e}")
                        metadata.success = False
                        metadata.error_message = str(e)
            
            # Step 5: Start containers
            logger.info(f"Starting {len(unit.containers)} containers...")
            self._start_containers(unit.containers)
            
        except Exception as e:
            logger.error(f"Backup failed for unit {unit.name}: {e}")
            metadata.success = False
            metadata.error_message = str(e)
            
            # Try to restart containers even if backup failed
            try:
                self._start_containers(unit.containers)
            except Exception as restart_error:
                logger.error(f"Failed to restart containers: {restart_error}")
        
        finally:
            metadata.duration_seconds = time.time() - start_time
            logger.info(f"Backup of {unit.name} completed in {metadata.duration_seconds:.2f}s")
            
            # Save metadata
            self._save_metadata(metadata)
        
        return metadata
    
    def _stop_containers(self, containers: List[ContainerInfo]):
        """
        Stop Docker containers.
        
        Args:
            containers: List of containers to stop
        """
        for container in containers:
            if not container.is_running:
                logger.debug(f"Container {container.name} already stopped")
                continue
            
            try:
                subprocess.run(
                    ['docker', 'stop', '-t', str(CONTAINER_STOP_TIMEOUT), container.id],
                    check=True,
                    capture_output=True
                )
                logger.debug(f"Stopped container: {container.name}")
            except subprocess.CalledProcessError as e:
                logger.error(f"Failed to stop container {container.name}: {e}")
                raise
    
    def _start_containers(self, containers: List[ContainerInfo]):
        """
        Start Docker containers.
        
        Args:
            containers: List of containers to start
        """
        for container in containers:
            try:
                subprocess.run(
                    ['docker', 'start', container.id],
                    check=True,
                    capture_output=True
                )
                logger.debug(f"Started container: {container.name}")
                
                # Wait a moment for container to initialize
                time.sleep(2)
                
            except subprocess.CalledProcessError as e:
                logger.error(f"Failed to start container {container.name}: {e}")
                # Continue with other containers even if one fails
    
    def _backup_recipes(self, unit: BackupUnit) -> Optional[str]:
        """
        Backup recipes (compose files and container inspect data).
        
        Args:
            unit: Backup unit
            
        Returns:
            Kopia snapshot ID or None
        """
        backup_path = self.config.backup_base_path / RECIPE_BACKUP_DIR / unit.name
        backup_path.mkdir(parents=True, exist_ok=True)
        
        try:
            # Backup docker-compose file if it exists
            if unit.compose_file and unit.compose_file.exists():
                compose_backup = backup_path / 'docker-compose.yml'
                with open(unit.compose_file, 'r') as src:
                    content = src.read()
                with open(compose_backup, 'w') as dst:
                    dst.write(content)
                logger.debug(f"Backed up compose file: {unit.compose_file}")
            
            # Backup container inspect data
            for container in unit.containers:
                inspect_file = backup_path / f"{container.name}_inspect.json"
                with open(inspect_file, 'w') as f:
                    json.dump(container.inspect_data, f, indent=2)
                logger.debug(f"Backed up inspect data for: {container.name}")
            
            # Create Kopia snapshot
            snapshot_id = self.repo.create_snapshot(
                str(backup_path),
                tags={
                    'type': 'recipe',
                    'unit': unit.name,
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            return snapshot_id
            
        except Exception as e:
            logger.error(f"Failed to backup recipes for {unit.name}: {e}")
            return None
    
    def _backup_volume(self, volume: VolumeInfo, unit: BackupUnit) -> Optional[str]:
        """
        Backup a Docker volume.
        
        Args:
            volume: Volume to backup
            unit: Backup unit this volume belongs to
            
        Returns:
            Kopia snapshot ID or None
        """
        try:
            logger.debug(f"Backing up volume: {volume.name}")
            
            # Create tar of volume and pipe to Kopia
            tar_cmd = [
                'tar', '-czf', '-',
                '-C', volume.mountpoint,
                '.'
            ]
            
            tar_process = subprocess.Popen(
                tar_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            
            snapshot_id = self.repo.create_snapshot_from_stdin(
                tar_process.stdout,
                path=f"{VOLUME_BACKUP_DIR}/{unit.name}/{volume.name}",
                tags={
                    'type': 'volume',
                    'unit': unit.name,
                    'volume': volume.name,
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            tar_process.wait()
            if tar_process.returncode != 0:
                stderr = tar_process.stderr.read().decode()
                logger.error(f"Tar failed for volume {volume.name}: {stderr}")
                return None
            
            return snapshot_id
            
        except Exception as e:
            logger.error(f"Failed to backup volume {volume.name}: {e}")
            return None
    
    def _backup_database(self, container: ContainerInfo, unit: BackupUnit) -> Optional[str]:
        """
        Backup a database container.
        
        Args:
            container: Database container
            unit: Backup unit this container belongs to
            
        Returns:
            Kopia snapshot ID or None
        """
        if not container.database_type:
            return None
        
        try:
            logger.debug(f"Backing up database: {container.name} ({container.database_type})")
            
            db_info = DATABASE_IMAGES[container.database_type]
            dump_cmd = self._build_database_dump_command(container, db_info)
            
            if not dump_cmd:
                logger.warning(f"Could not build dump command for {container.name}")
                return None
            
            # Execute dump command in container
            docker_cmd = ['docker', 'exec', container.id] + dump_cmd.split()
            
            dump_process = subprocess.Popen(
                docker_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            
            snapshot_id = self.repo.create_snapshot_from_stdin(
                dump_process.stdout,
                path=f"{DATABASE_BACKUP_DIR}/{unit.name}/{container.name}",
                tags={
                    'type': 'database',
                    'database_type': container.database_type,
                    'unit': unit.name,
                    'container': container.name,
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            dump_process.wait()
            if dump_process.returncode != 0:
                stderr = dump_process.stderr.read().decode()
                logger.error(f"Database dump failed for {container.name}: {stderr}")
                return None
            
            return snapshot_id
            
        except Exception as e:
            logger.error(f"Failed to backup database {container.name}: {e}")
            return None
    
    def _build_database_dump_command(self, 
                                    container: ContainerInfo,
                                    db_info: Dict[str, Any]) -> Optional[str]:
        """
        Build database dump command based on database type.
        
        Args:
            container: Database container
            db_info: Database configuration info
            
        Returns:
            Dump command string or None
        """
        dump_template = db_info['dump_command']
        
        # Get credentials from environment
        env = container.environment
        
        # Get user
        user = None
        if 'env_user' in db_info:
            user = env.get(db_info['env_user'])
        if not user and 'default_user' in db_info:
            user = db_info['default_user']
        
        # Get password
        password = None
        if 'env_password' in db_info:
            password = env.get(db_info['env_password'])
        elif 'env_root_password' in db_info:
            password = env.get(db_info['env_root_password'])
        
        # Build command
        if '{user}' in dump_template and user:
            dump_template = dump_template.replace('{user}', user)
        
        if '{password}' in dump_template and password:
            dump_template = dump_template.replace('{password}', password)
        
        return dump_template
    
    def _save_metadata(self, metadata: BackupMetadata):
        """
        Save backup metadata.
        
        Args:
            metadata: Backup metadata to save
        """
        metadata_dir = self.config.backup_base_path / 'metadata'
        metadata_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"{metadata.unit_name}_{metadata.timestamp.strftime('%Y%m%d_%H%M%S')}.json"
        metadata_file = metadata_dir / filename
        
        with open(metadata_file, 'w') as f:
            json.dump(metadata.to_dict(), f, indent=2)
        
        logger.debug(f"Saved metadata to {metadata_file}")
```

## File: kopia_docka/restore.py

```python
"""
Restore management module for Kopia-Docka.

This module handles interactive restoration of Docker containers and volumes
from Kopia backups.
"""

import json
import logging
import subprocess
import tempfile
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Any

from .types import RestorePoint, BackupUnit
from .config import Config
from .repository import KopiaRepository
from .constants import (
    RECIPE_BACKUP_DIR,
    VOLUME_BACKUP_DIR,
    DATABASE_BACKUP_DIR
)


logger = logging.getLogger(__name__)


class RestoreManager:
    """
    Manages restoration of Docker containers and volumes from backups.
    
    This class provides an interactive wizard for selecting and restoring
    backup units from Kopia snapshots.
    """
    
    def __init__(self, config: Config):
        """
        Initialize restore manager.
        
        Args:
            config: Application configuration
        """
        self.config = config
        self.repo = KopiaRepository(config)
    
    def interactive_restore(self):
        """
        Launch interactive restore wizard.
        
        This guides the user through selecting a backup to restore
        and provides commands to restore the service.
        """
        print("\n" + "=" * 60)
        print("Kopia-Docka Restore Wizard")
        print("=" * 60)
        
        # List available restore points
        restore_points = self._find_restore_points()
        
        if not restore_points:
            print("\nNo backups found to restore.")
            return
        
        # Display available restore points
        print("\nAvailable restore points:\n")
        for idx, point in enumerate(restore_points, 1):
            print(f"{idx}. {point.unit_name} - {point.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"   Volumes: {len(point.volume_snapshots)}, "
                  f"Databases: {len(point.database_snapshots)}")
        
        # Select restore point
        while True:
            try:
                choice = input("\nSelect restore point (number): ").strip()
                idx = int(choice) - 1
                if 0 <= idx < len(restore_points):
                    selected = restore_points[idx]
                    break
                print("Invalid selection. Please try again.")
            except (ValueError, KeyboardInterrupt):
                print("\nRestore cancelled.")
                return
        
        print(f"\nSelected: {selected.unit_name} from {selected.timestamp}")
        
        # Confirm restoration
        print("\nThis will guide you through restoring:")
        print(f"  - Recipe/configuration files")
        print(f"  - {len(selected.volume_snapshots)} volumes")
        print(f"  - {len(selected.database_snapshots)} database dumps")
        
        confirm = input("\nProceed with restore? (yes/no): ").strip().lower()
        if confirm != 'yes':
            print("Restore cancelled.")
            return
        
        # Perform restore
        self._restore_unit(selected)
    
    def _find_restore_points(self) -> List[RestorePoint]:
        """
        Find all available restore points.
        
        Returns:
            List of restore points
        """
        restore_points = []
        
        # Get all recipe snapshots (they define restore points)
        snapshots = self.repo.list_snapshots(tag_filter={'type': 'recipe'})
        
        for snap in snapshots:
            tags = snap.get('tags', {})
            unit_name = tags.get('unit')
            timestamp_str = tags.get('timestamp')
            
            if not unit_name or not timestamp_str:
                continue
            
            try:
                timestamp = datetime.fromisoformat(timestamp_str)
            except ValueError:
                continue
            
            # Find associated volume and database snapshots
            point = RestorePoint(
                unit_name=unit_name,
                timestamp=timestamp,
                recipe_snapshot=snap['id']
            )
            
            # Find volume snapshots
            volume_snaps = self.repo.list_snapshots(
                tag_filter={
                    'type': 'volume',
                    'unit': unit_name
                }
            )
            for vol_snap in volume_snaps:
                vol_tags = vol_snap.get('tags', {})
                vol_timestamp = vol_tags.get('timestamp')
                if vol_timestamp and self._timestamps_match(timestamp_str, vol_timestamp):
                    volume_name = vol_tags.get('volume')
                    if volume_name:
                        point.volume_snapshots[volume_name] = vol_snap['id']
            
            # Find database snapshots
            db_snaps = self.repo.list_snapshots(
                tag_filter={
                    'type': 'database',
                    'unit': unit_name
                }
            )
            for db_snap in db_snaps:
                db_tags = db_snap.get('tags', {})
                db_timestamp = db_tags.get('timestamp')
                if db_timestamp and self._timestamps_match(timestamp_str, db_timestamp):
                    container_name = db_tags.get('container')
                    if container_name:
                        point.database_snapshots[container_name] = db_snap['id']
            
            restore_points.append(point)
        
        # Sort by timestamp (newest first)
        restore_points.sort(key=lambda p: p.timestamp, reverse=True)
        
        return restore_points
    
    def _timestamps_match(self, ts1: str, ts2: str, tolerance_seconds: int = 300) -> bool:
        """
        Check if two timestamps are close enough to be from the same backup.
        
        Args:
            ts1: First timestamp string
            ts2: Second timestamp string
            tolerance_seconds: Maximum difference in seconds
            
        Returns:
            True if timestamps match within tolerance
        """
        try:
            dt1 = datetime.fromisoformat(ts1)
            dt2 = datetime.fromisoformat(ts2)
            diff = abs((dt1 - dt2).total_seconds())
            return diff <= tolerance_seconds
        except ValueError:
            return False
    
    def _restore_unit(self, restore_point: RestorePoint):
        """
        Restore a backup unit.
        
        Args:
            restore_point: Restore point to restore
        """
        print("\n" + "-" * 60)
        print("Starting restoration process...")
        print("-" * 60)
        
        # Create restore directory
        restore_dir = Path(tempfile.mkdtemp(prefix='kopia-docka-restore-'))
        print(f"\nRestore directory: {restore_dir}")
        
        try:
            # Step 1: Restore recipes
            print("\n1. Restoring recipes...")
            recipe_dir = self._restore_recipe(restore_point, restore_dir)
            
            # Step 2: Display volume restore instructions
            if restore_point.volume_snapshots:
                print("\n2. Volume restoration:")
                self._display_volume_restore_instructions(restore_point, restore_dir)
            
            # Step 3: Display database restore instructions
            if restore_point.database_snapshots:
                print("\n3. Database restoration:")
                self._display_database_restore_instructions(restore_point, restore_dir)
            
            # Step 4: Display service restart instructions
            print("\n4. Service restart instructions:")
            self._display_restart_instructions(recipe_dir)
            
            print("\n" + "=" * 60)
            print("Restoration guide complete!")
            print("Follow the instructions above to restore your service.")
            print("=" * 60)
            
        except Exception as e:
            logger.error(f"Restore failed: {e}")
            print(f"\nError during restore: {e}")
    
    def _restore_recipe(self, restore_point: RestorePoint, restore_dir: Path) -> Path:
        """
        Restore recipe files.
        
        Args:
            restore_point: Restore point
            restore_dir: Directory to restore to
            
        Returns:
            Path to restored recipe directory
        """
        recipe_dir = restore_dir / 'recipes'
        recipe_dir.mkdir(parents=True, exist_ok=True)
        
        # Restore recipe snapshot
        self.repo.restore_snapshot(restore_point.recipe_snapshot, str(recipe_dir))
        
        print(f"   ✓ Recipes restored to: {recipe_dir}")
        
        # List restored files
        for file in recipe_dir.rglob('*'):
            if file.is_file():
                print(f"     - {file.relative_to(recipe_dir)}")
        
        return recipe_dir
    
    def _display_volume_restore_instructions(self, restore_point: RestorePoint, restore_dir: Path):
        """
        Display instructions for restoring volumes.
        
        Args:
            restore_point: Restore point
            restore_dir: Directory for restoration
        """
        print("\n   To restore volumes, run these commands:\n")
        
        for volume_name, snapshot_id in restore_point.volume_snapshots.items():
            volume_restore_dir = restore_dir / 'volumes' / volume_name
            
            print(f"   # Restore volume: {volume_name}")
            print(f"   mkdir -p {volume_restore_dir}")
            print(f"   kopia snapshot restore {snapshot_id} {volume_restore_dir}")
            print(f"   docker volume create {volume_name}")
            print(f"   docker run --rm -v {volume_name}:/restore -v {volume_restore_dir}:/backup \\")
            print(f"          alpine sh -c 'cd /restore && tar -xzf /backup/*.tar.gz'")
            print()
    
    def _display_database_restore_instructions(self, restore_point: RestorePoint, restore_dir: Path):
        """
        Display instructions for restoring databases.
        
        Args:
            restore_point: Restore point
            restore_dir: Directory for restoration
        """
        print("\n   Database restore commands:\n")
        
        for container_name, snapshot_id in restore_point.database_snapshots.items():
            db_restore_file = restore_dir / 'databases' / f"{container_name}.sql"
            
            print(f"   # Restore database dump for: {container_name}")
            print(f"   mkdir -p {db_restore_file.parent}")
            print(f"   kopia snapshot restore {snapshot_id} {db_restore_file}")
            print(f"   # Then import into running container:")
            print(f"   docker exec -i {container_name} sh -c 'cat > /tmp/restore.sql'")
            print(f"   # Run appropriate restore command based on database type")
            print()
    
    def _display_restart_instructions(self, recipe_dir: Path):
        """
        Display instructions for restarting services.
        
        Args:
            recipe_dir: Directory containing restored recipes
        """
        compose_file = recipe_dir / 'docker-compose.yml'
        
        if compose_file.exists():
            print("\n   To restart using Docker Compose:")
            print(f"   cd {recipe_dir}")
            print(f"   docker-compose up -d")
        else:
            print("\n   To restart containers manually:")
            print("   Review the inspect JSON files in the recipe directory")
            print("   and use 'docker run' with the appropriate parameters.")
            print(f"   Inspect files location: {recipe_dir}")


class RestoreHelper:
    """
    Helper class for restoration operations.
    
    Provides utility methods for reconstructing Docker commands
    from inspect data.
    """
    
    @staticmethod
    def reconstruct_docker_run(inspect_data: Dict[str, Any]) -> str:
        """
        Reconstruct docker run command from inspect data.
        
        Args:
            inspect_data: Docker inspect JSON data
            
        Returns:
            Docker run command string
        """
        cmd_parts = ['docker run -d']
        
        config = inspect_data.get('Config', {})
        host_config = inspect_data.get('HostConfig', {})
        
        # Name
        name = inspect_data.get('Name', '').lstrip('/')
        if name:
            cmd_parts.append(f'--name {name}')
        
        # Environment variables
        for env in config.get('Env', []):
            if '=' in env:
                cmd_parts.append(f'-e "{env}"')
        
        # Ports
        for container_port, host_bindings in host_config.get('PortBindings', {}).items():
            if host_bindings:
                for binding in host_bindings:
                    host_port = binding.get('HostPort')
                    if host_port:
                        cmd_parts.append(f'-p {host_port}:{container_port}')
        
        # Volumes
        for mount in inspect_data.get('Mounts', []):
            if mount['Type'] == 'volume':
                cmd_parts.append(f'-v {mount["Name"]}:{mount["Destination"]}')
            elif mount['Type'] == 'bind':
                cmd_parts.append(f'-v {mount["Source"]}:{mount["Destination"]}')
        
        # Restart policy
        restart = host_config.get('RestartPolicy', {})
        if restart.get('Name'):
            if restart['Name'] == 'no':
                pass  # Default
            elif restart['Name'] == 'always':
                cmd_parts.append('--restart always')
            elif restart['Name'] == 'unless-stopped':
                cmd_parts.append('--restart unless-stopped')
            elif restart['Name'] == 'on-failure':
                max_retry = restart.get('MaximumRetryCount', 0)
                cmd_parts.append(f'--restart on-failure:{max_retry}')
        
        # Image (must be last)
        image = config.get('Image')
        if image:
            cmd_parts.append(image)
        
        # Command
        cmd = config.get('Cmd')
        if cmd:
            cmd_parts.extend(cmd)
        
        return ' \\\n    '.join(cmd_parts)